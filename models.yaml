defaults:
  text_max_tokens: 200000
  context_limit: 200000  # Default is no limit; set per-model to enable auto-trimming

models:
  text:
    - poe_name: Gemini-2.5-Flash
      context_limit: 500000
    - poe_name: Gemini-2.5-Pro
      context_limit: 200000
    - poe_name: Claude-3.5-Sonnet
      context_limit: 200000
    - poe_name: Claude-Haiku-4.5
      context_limit: 150000
    - poe_name: Claude-Sonnet-4.5
      context_limit: 50000
    - poe_name: GPT-4.1
      context_limit: 200000
    - poe_name: gpt-5.2-instant
      context_limit: 100000
    - poe_name: GPT-4.1-mini
      context_limit: 100000
    - poe_name: o4-mini
      context_limit: 100000
    - poe_name: o3-mini-high
      context_limit: 100000
    - poe_name: DeepSeek-R1
      context_limit: 168000
    - poe_name: deepseek-v3
      context_limit: 168000
    - poe_name: Mistral-Small-3.1
      context_limit: 100000
    - poe_name: Mistral-Large-2
      context_limit: 100000
    - poe_name: Perplexity-Sonar
      context_limit: 100000
    - poe_name: GLM-4.7
      context_limit: 100000
    - poe_name: Kimi-K2-Instruct
      context_limit: 100000
    - poe_name: GPT-OSS-120B-T
      context_limit: 200000
    - poe_name: Qwen3-Coder
      context_limit: 200000
    - poe_name: minimax-m2.1
      context_limit: 205000
  image:
    - poe_name: Imagen-4-Ultra
    - poe_name: nano-banana
    - poe_name: qwen-edit
  video:
    - poe_name: Wan-2.2
    - poe_name: Wan-2.5
    - poe_name: veo-v3.1-fast

  audio:
    - poe_name: ElevenLabs-v3
